from src.model_converter import BlipONNXConverter
from src.onnx_tester import ONNXModelTester
from PIL import Image
import os


def test_with_real_image():
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    """
    print("=== –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º ===\n")

    # –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    image_path = "../step2_fastapi_inference/test_images/img.jpg"

    if not os.path.exists(image_path):
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    image = Image.open(image_path)
    print(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")
    print(f"–†–µ–∂–∏–º: {image.mode}")

    # –¢–µ—Å—Ç PyTorch –º–æ–¥–µ–ª–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    print("\n1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PyTorch –º–æ–¥–µ–ª–∏:")
    converter = BlipONNXConverter()
    converter.load_model()

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    inputs = converter.processor(image, return_tensors="pt")
    print(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {inputs.pixel_values.shape}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è caption PyTorch –º–æ–¥–µ–ª—å—é
    import torch

    with torch.no_grad():
        out = converter.model.generate(**inputs, max_length=50)

    caption = converter.processor.decode(out[0], skip_special_tokens=True)
    print(f"PyTorch –º–æ–¥–µ–ª—å caption: '{caption}'")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏:")
    onnx_path = "models/blip_model.onnx"

    if not os.path.exists(onnx_path):
        print("‚ùå ONNX –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º...")
        converter.convert_to_onnx(onnx_path)

    # –¢–µ—Å—Ç ONNX —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    tester = ONNXModelTester(onnx_path)
    tester.load_onnx_model()

    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ ONNX
    try:
        inputs_onnx = converter.processor(image, return_tensors="pt")
        image_input = inputs_onnx.pixel_values.numpy()
        input_ids = torch.tensor([[converter.processor.tokenizer.bos_token_id]]).numpy()

        print("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ONNX:")
        print(f"  - image: {image_input.shape}")
        print(f"  - input_ids: {input_ids.shape}")

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ö–æ–¥–æ–≤
        input_variants = [
            {"image": image_input, "input_ids": input_ids},
            {"pixel_values": image_input, "input_ids": input_ids},
        ]

        success = False
        for i, variant in enumerate(input_variants):
            try:
                print(f"\n–ü—Ä–æ–±—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç {i+1}: {list(variant.keys())}")
                outputs = tester.session.run(None, variant)
                print(f"‚úÖ ONNX —Ä–∞–±–æ—Ç–∞–µ—Ç! –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞: {outputs[0].shape}")
                success = True
                break
            except Exception as e:
                print(f"‚ùå –í–∞—Ä–∏–∞–Ω—Ç {i+1} –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {str(e)[:100]}...")

        if not success:
            print("\n‚ö†Ô∏è ONNX –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ PyTorch –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            print("–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ BLIP")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ONNX: {e}")

    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("üì∏ PyTorch –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    print(f"üí¨ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '{caption}'")


if __name__ == "__main__":
    test_with_real_image()
