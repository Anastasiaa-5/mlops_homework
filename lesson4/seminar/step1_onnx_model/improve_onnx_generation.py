import numpy as np
import torch
from PIL import Image
from src.onnx_tester import ONNXModelTester


def iterative_onnx_generation(onnx_tester, image, max_tokens=10):
    """
    –ü–æ–ø—ã—Ç–∫–∞ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å ONNX –º–æ–¥–µ–ª—å—é
    """
    print("üîÑ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å ONNX...")

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    inputs = onnx_tester.processor(image, return_tensors="pt")
    image_input = inputs.pixel_values.numpy()

    # –ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤
    token_id = getattr(onnx_tester.processor.tokenizer, "bos_token_id", None)
    if token_id is None:
        token_id = getattr(onnx_tester.processor.tokenizer, "cls_token_id", 101)

    # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
    current_tokens = [token_id]
    generated_tokens = []

    print(f"–ù–∞—á–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω: {token_id}")

    for step in range(max_tokens):
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º input_ids —Ç–µ–∫—É—â–µ–π –¥–ª–∏–Ω—ã (–∑–∞–ø–æ–ª–Ω—è–µ–º –¥–æ 16)
        if len(current_tokens) < 16:
            # –î–æ–±–∞–≤–ª—è–µ–º padding
            input_ids = current_tokens + [token_id] * (16 - len(current_tokens))
        else:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 16 —Ç–æ–∫–µ–Ω–æ–≤
            input_ids = current_tokens[-16:]

        input_ids_array = np.array([input_ids], dtype=np.int64)

        # ONNX –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        onnx_inputs = {"image": image_input, "input_ids": input_ids_array}

        try:
            outputs = onnx_tester.session.run(None, onnx_inputs)
            logits = outputs[0]  # [1, 16, 30524]

            # –ë–µ—Ä–µ–º –ª–æ–≥–∏—Ç—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç–æ–∫–µ–Ω–∞
            last_token_logits = logits[
                0, len(current_tokens) - 1 if len(current_tokens) <= 16 else 15, :
            ]
            predicted_id = int(np.argmax(last_token_logits))

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
            try:
                token = onnx_tester.processor.tokenizer.decode([predicted_id])
                print(
                    f"  –®–∞–≥ {step+1}: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω —Ç–æ–∫–µ–Ω '{token}' (ID: {predicted_id})"
                )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                if predicted_id == 102:  # [SEP] token
                    print("  üõë –í—Å—Ç—Ä–µ—Ç–∏–ª–∏ [SEP] —Ç–æ–∫–µ–Ω, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
                    break

                current_tokens.append(predicted_id)
                generated_tokens.append(predicted_id)

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ {predicted_id}: {e}")
                break

        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ ONNX –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ —à–∞–≥–µ {step+1}: {e}")
            break

    # –ü—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    if generated_tokens:
        try:
            full_text = onnx_tester.processor.tokenizer.decode(
                generated_tokens, skip_special_tokens=True
            )
            print(f"\nüéØ –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{full_text}'")
            return full_text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return None
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã")
        return None


def main():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π ONNX –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π"""
    print("=== –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: —É–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è ONNX ===\n")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_path = "../step2_fastapi_inference/test_images/img.jpg"
    image = Image.open(image_path).convert("RGB")
    print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}, —Ä–∞–∑–º–µ—Ä: {image.size}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ONNX —Ç–µ—Å—Ç–µ—Ä–∞
    onnx_path = "models/blip_model.onnx"
    tester = ONNXModelTester(onnx_path)
    tester.load_onnx_model()

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PyTorch
    print("\n1. PyTorch baseline (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è):")
    from src.model_converter import BlipONNXConverter

    converter = BlipONNXConverter()
    converter.load_model()

    inputs = converter.processor(image, return_tensors="pt")
    with torch.no_grad():
        out = converter.model.generate(**inputs, max_length=50)
    pytorch_caption = converter.processor.decode(out[0], skip_special_tokens=True)
    print(f"   PyTorch: '{pytorch_caption}'")

    # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π
    print("\n2. –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è ONNX –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:")
    onnx_caption = iterative_onnx_generation(tester, image, max_tokens=8)

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüìä –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ:")
    print(f"   ‚úÖ PyTorch (—ç—Ç–∞–ª–æ–Ω): '{pytorch_caption}'")
    print(f"   ‚ö†Ô∏è  ONNX –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ:   '{onnx_caption or '–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å'}'")

    print("\nüí° –í—ã–≤–æ–¥—ã:")
    print("   ‚Ä¢ PyTorch –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—ã–±–∞–∫–∞")
    print("   ‚Ä¢ ONNX –º–æ–¥–µ–ª—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞, –Ω–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –Ω–µ—Ç–æ—á–Ω–∞")
    print("   ‚Ä¢ –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PyTorch –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    print("   ‚Ä¢ ONNX –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")


if __name__ == "__main__":
    main()
