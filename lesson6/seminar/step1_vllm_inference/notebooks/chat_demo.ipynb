{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama Chat Demo\n",
    "\n",
    "Запустить: `make start && make pull`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.llm_client import OllamaClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OllamaClient()\n",
    "\n",
    "if client.health_check():\n",
    "    print(\"✅ Ollama is running!\")\n",
    "else:\n",
    "    print(\"❌ Ollama not responding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.get_models()\n",
    "print(\"Available models:\")\n",
    "for model in models:\n",
    "    print(f\"  - {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is machine learning in one sentence?\"}\n",
    "]\n",
    "\n",
    "response = client.chat_completion(messages=messages, temperature=0.7, max_tokens=200)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain what is MLOps in 3 sentences.\"}\n",
    "]\n",
    "\n",
    "for chunk in client.chat_completion_stream(messages=messages, temperature=0.7, max_tokens=300):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant expert in MLOps.\"}\n",
    "]\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": \"What are the main stages of ML lifecycle?\"})\n",
    "response = client.chat_completion(messages=conversation, temperature=0.7, max_tokens=512)\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.append({\"role\": \"user\", \"content\": \"Can you explain the deployment stage in more detail?\"})\n",
    "response = client.chat_completion(messages=conversation, temperature=0.7, max_tokens=512)\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Ты полезный AI ассистент, эксперт в области машинного обучения и MLOps.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Что такое MLOps и зачем он нужен?\"}\n",
    "]\n",
    "\n",
    "response = client.chat_completion(messages=messages, temperature=0.7, max_tokens=512)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
